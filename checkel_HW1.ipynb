{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYBvZS0vQ-gr"
   },
   "source": [
    "# CS 583-C-Homework 1\n",
    "## Neural networks\n",
    "\n",
    "---\n",
    "\n",
    "### ***Fill your details below***\n",
    "### Name: Corey Heckel\n",
    "### CWID: 10462028\n",
    "### Email ID: checkel\n",
    "### References: ***Cite your references here***\n",
    "\n",
    "\n",
    "---\n",
    "### Submission guidelines:\n",
    "\n",
    "#### 1. Submit this notebook along with its PDF version. You can do this by clicking File->Print->\"Save as PDF\"\n",
    "\n",
    "#### 2. Name the file as \"<mailID_HWnumber.extension>\".  \n",
    "\n",
    "For example, mailID is abcdefg @stevens.edu then name the files as abcdefg_HW1.ipynb and abcdefg_HW1.pdf.\n",
    "\n",
    "#### 3. Please do not Zip your files.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PtKvmZx-WmUu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.4.1-cp39-cp39-win_amd64.whl (199.3 MB)\n",
      "Requirement already satisfied: sympy in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Collecting typing-extensions>=4.8.0\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Installing collected packages: typing-extensions, torch\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.1.1\n",
      "    Uninstalling typing-extensions-4.1.1:\n",
      "      Successfully uninstalled typing-extensions-4.1.1\n",
      "Successfully installed torch-2.4.1 typing-extensions-4.12.2\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.19.1-cp39-cp39-win_amd64.whl (1.3 MB)\n",
      "Requirement already satisfied: torch==2.4.1 in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from torchvision) (2.4.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\wheel\\appdata\\roaming\\python\\python39\\site-packages (from torchvision) (1.21.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (1.10.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (2.7.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from torch==2.4.1->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from jinja2->torch==2.4.1->torchvision) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\wheel\\anaconda3\\lib\\site-packages (from sympy->torch==2.4.1->torchvision) (1.2.1)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.19.1\n"
     ]
    }
   ],
   "source": [
    "#@title Installing Pytorch\n",
    "\n",
    "!pip install torch\n",
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bGU6NwlsXFSt"
   },
   "outputs": [],
   "source": [
    "#@title Import Dependencies\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_bNfVLRUYqZA"
   },
   "outputs": [],
   "source": [
    "#@title Define Hyperparameters\n",
    "\n",
    "input_size = 784 # img_size = (28,28) ---> 28*28=784 in total\n",
    "hidden_size = 500 # number of nodes at hidden layer\n",
    "num_classes = 10 # number of output classes discrete range [0,9]\n",
    "num_epochs = 5 # number of times which the entire dataset is passed throughout the model\n",
    "batch_size = 100 # the size of input data took for one iteration\n",
    "lr = 1e-3 # size of step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "lCsBCXMwbpH5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 9912422/9912422 [00:06<00:00, 1563450.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 1314092.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 9686068.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 919693.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Downloading MNIST data\n",
    "\n",
    "train_data = dsets.MNIST(root = './data', train = True,\n",
    "                        transform = transforms.ToTensor(), download = True)\n",
    "\n",
    "test_data = dsets.MNIST(root = './data', train = False,\n",
    "                       transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rfDPBdnYgfGp"
   },
   "outputs": [],
   "source": [
    "#@title Loading the data\n",
    "\n",
    "train_gen = torch.utils.data.DataLoader(dataset = train_data,\n",
    "                                             batch_size = batch_size,\n",
    "                                             shuffle = True)\n",
    "\n",
    "test_gen = torch.utils.data.DataLoader(dataset = test_data,\n",
    "                                      batch_size = batch_size,\n",
    "                                      shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z_yHL9bPDI-"
   },
   "source": [
    "## Q1. (50 points): design a neural network, provide justification.\n",
    "\n",
    "PyTorch neural network documentation: https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fL-YXTvghaz_"
   },
   "outputs": [],
   "source": [
    "#@title Define model class\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, num_classes):\n",
    "    super(Net,self).__init__()\n",
    "    ''' code to build the model '''\n",
    "    self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "\n",
    "  def forward(self,x):\n",
    "    ''' code to define the forward pass '''\n",
    "    output = self.fc1(x)\n",
    "    output = self.relu(output)\n",
    "    output = self.fc2(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "self.fc1 represents the first fully connected hidden layer going from the input size (784 neurons) to the hidden size (500 neurons). ReLU is used as the activation function due to its ability to introduce non-linearity and efficiency. There is then a second fully connected layer which goes from the hidden size(500 neurons) to then the number of classes(10 neurons). The forward method passes the input data through the first fully connected layer, activated the ReLU function, passes the output through the second fully connected layer, resulting in a prediction of the class the input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-3EPEqbjjfAT"
   },
   "outputs": [],
   "source": [
    "#@title Build the model\n",
    "\n",
    "net = Net(input_size, hidden_size, num_classes)\n",
    "if torch.cuda.is_available():\n",
    "  net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ePLIwvAFj2zH"
   },
   "outputs": [],
   "source": [
    "#@title Define loss-function & optimizer\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam( net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6IZ2UotP39e"
   },
   "source": [
    "##Q2.\n",
    "\n",
    "##a) In the code provided below, What is the meaning of the \"loss.backward()\" step? Please explain the functionality. (15 pts)\n",
    "\n",
    "This step computes the gradients of the loss function with respect to the weights and bias. This indicated how to adjust the parameters to reduce loss.  This is called backpropagation where the error is propagated backward through the network.\n",
    "\n",
    "##b) What is the meaning of \"optimizer.step()\" and what does it do? (15 pts)\n",
    "\n",
    "After computing the gradients in the previous step, this updates the model parameters using the calculated gradients to minimize the loss. Ultimately, this is used to optimize the parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "u75Xa5VckuTH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.3856\n",
      "Epoch [1/5], Step [200/600], Loss: 0.3547\n",
      "Epoch [1/5], Step [300/600], Loss: 0.2332\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1790\n",
      "Epoch [1/5], Step [500/600], Loss: 0.1084\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1370\n",
      "Epoch [2/5], Step [100/600], Loss: 0.1695\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1396\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0869\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1663\n",
      "Epoch [2/5], Step [500/600], Loss: 0.1305\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0850\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0793\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0579\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0778\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0564\n",
      "Epoch [3/5], Step [500/600], Loss: 0.1795\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0422\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0360\n",
      "Epoch [4/5], Step [200/600], Loss: 0.1245\n",
      "Epoch [4/5], Step [300/600], Loss: 0.1650\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0849\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0566\n",
      "Epoch [4/5], Step [600/600], Loss: 0.1229\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0293\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0350\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0260\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0751\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0282\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0640\n"
     ]
    }
   ],
   "source": [
    "#@title Training the model\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  for i ,(images,labels) in enumerate(train_gen):\n",
    "    images = Variable(images.view(-1,28*28))\n",
    "    labels = Variable(labels)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(images)\n",
    "    loss = loss_function(outputs, labels)\n",
    "    loss.backward() #Q2a (15 points): What is the meaning of this step? Please explain the functionality.\n",
    "    optimizer.step() #Q2b (15 points): What is the meaning of this step? Please explain the functionality.\n",
    "\n",
    "    if (i+1) % 100 == 0:\n",
    "      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'%(epoch+1, num_epochs, i+1, len(train_data)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjMFDJwOQohr"
   },
   "source": [
    "#Q3 (20 points): Discuss the results. Is the neural network doing a good job?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DTPvMW5jHB9X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 97.910 %\n"
     ]
    }
   ],
   "source": [
    "#@title Evaluating the accuracy of the model\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for images,labels in test_gen:\n",
    "  images = Variable(images.view(-1,28*28))\n",
    "  labels = labels\n",
    "\n",
    "  output = net(images)\n",
    "  _, predicted = torch.max(output,1)\n",
    "  correct += (predicted == labels).sum()\n",
    "  total += labels.size(0)\n",
    "\n",
    "print('Accuracy of the model: %.3f %%' %((100*correct)/(total+1)))\n",
    "#Q3 (20 points): How to interpret the results? Is the neural network does a good job?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy determines how well the model performs to unseen data. High accuracy indicates that the model does a good job of generalizing from the training data to the unseen data. But if the accuracy is low, then it indicates that the model does not do a good job at doing this. It could be due to issues such as underfitting or overfitting. Similarly, if the loss decreases during the training it indicates that the model is learning. \n",
    "\n",
    "In this example, the neural network is doing a good job. The accuracy of the model is high at 97.91%. Similarly as seen throughout the training of the model, there is a tend of a decreasing loss indicating that the model is learning efficiently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
